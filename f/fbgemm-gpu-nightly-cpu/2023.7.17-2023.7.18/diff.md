# Comparing `tmp/fbgemm_gpu_nightly_cpu-2023.7.17-cp39-cp39-manylinux2014_x86_64.whl.zip` & `tmp/fbgemm_gpu_nightly_cpu-2023.7.18-cp39-cp39-manylinux2014_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,43 +1,43 @@
-Zip file size: 3200068 bytes, number of entries: 41
--rw-r--r--  2.0 unx      567 b- defN 23-Jul-17 13:02 fbgemm_gpu/__init__.py
--rw-r--r--  2.0 unx    14920 b- defN 23-Jul-17 13:02 fbgemm_gpu/_fbgemm_gpu_docs.py
--rw-r--r--  2.0 unx     2747 b- defN 23-Jul-17 13:02 fbgemm_gpu/batched_unary_embeddings_ops.py
--rw-r--r--  2.0 unx      818 b- defN 23-Jul-17 13:02 fbgemm_gpu/enums.py
--rwxr-xr-x  2.0 unx 10721352 b- defN 23-Jul-17 13:02 fbgemm_gpu/fbgemm_gpu_py.so
--rw-r--r--  2.0 unx     5648 b- defN 23-Jul-17 13:02 fbgemm_gpu/metrics.py
--rw-r--r--  2.0 unx     2339 b- defN 23-Jul-17 13:02 fbgemm_gpu/permute_pooled_embedding_modules.py
--rw-r--r--  2.0 unx     2737 b- defN 23-Jul-17 13:02 fbgemm_gpu/permute_pooled_embedding_modules_split.py
--rw-r--r--  2.0 unx     7682 b- defN 23-Jul-17 13:02 fbgemm_gpu/quantize_comm.py
--rw-r--r--  2.0 unx     4005 b- defN 23-Jul-17 13:02 fbgemm_gpu/quantize_utils.py
--rw-r--r--  2.0 unx     5745 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_embedding_configs.py
--rw-r--r--  2.0 unx     6661 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_embedding_inference_converter.py
--rw-r--r--  2.0 unx      525 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_embedding_optimizer_ops.py
--rw-r--r--  2.0 unx    19751 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_embedding_utils.py
--rw-r--r--  2.0 unx     2170 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_table_batched_embeddings_ops.py
--rw-r--r--  2.0 unx     3433 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_table_batched_embeddings_ops_common.py
--rw-r--r--  2.0 unx    60371 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_table_batched_embeddings_ops_inference.py
--rw-r--r--  2.0 unx    73634 b- defN 23-Jul-17 13:02 fbgemm_gpu/split_table_batched_embeddings_ops_training.py
--rw-r--r--  2.0 unx    39550 b- defN 23-Jul-17 13:02 fbgemm_gpu/ssd_split_table_batched_embeddings_ops.py
--rw-r--r--  2.0 unx      910 b- defN 23-Jul-17 13:02 fbgemm_gpu/uvm.py
--rw-r--r--  2.0 unx     1603 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/__init__.py
--rw-r--r--  2.0 unx     4076 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_adagrad.py
--rw-r--r--  2.0 unx     3291 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_adam.py
--rw-r--r--  2.0 unx     2775 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_approx_rowwise_adagrad_with_weight_decay.py
--rw-r--r--  2.0 unx     1906 b- defN 23-Jul-17 12:56 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_args.py
--rw-r--r--  2.0 unx     3291 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_lamb.py
--rw-r--r--  2.0 unx     3040 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_lars_sgd.py
--rw-r--r--  2.0 unx     2316 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_none.py
--rw-r--r--  2.0 unx     2996 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_partial_rowwise_adam.py
--rw-r--r--  2.0 unx     2996 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_partial_rowwise_lamb.py
--rw-r--r--  2.0 unx     4320 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad.py
--rw-r--r--  2.0 unx     6067 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad_with_counter.py
--rw-r--r--  2.0 unx     2768 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad_with_weight_decay.py
--rw-r--r--  2.0 unx     4602 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_weighted_adagrad.py
--rw-r--r--  2.0 unx     3658 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_sgd.py
--rw-r--r--  2.0 unx      635 b- defN 23-Jul-17 12:56 fbgemm_gpu/split_embedding_optimizer_codegen/optimizer_args.py
--rw-r--r--  2.0 unx     6136 b- defN 23-Jul-17 13:00 fbgemm_gpu/split_embedding_optimizer_codegen/split_embedding_optimizer_rowwise_adagrad.py
--rw-r--r--  2.0 unx     2934 b- defN 23-Jul-17 13:02 fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/METADATA
--rw-r--r--  2.0 unx      105 b- defN 23-Jul-17 13:02 fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 23-Jul-17 13:02 fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     4534 b- defN 23-Jul-17 13:02 fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/RECORD
-41 files, 11039625 bytes uncompressed, 3192430 bytes compressed:  71.1%
+Zip file size: 3200063 bytes, number of entries: 41
+-rw-r--r--  2.0 unx      567 b- defN 23-Jul-18 13:00 fbgemm_gpu/__init__.py
+-rw-r--r--  2.0 unx    14920 b- defN 23-Jul-18 13:00 fbgemm_gpu/_fbgemm_gpu_docs.py
+-rw-r--r--  2.0 unx     2747 b- defN 23-Jul-18 13:00 fbgemm_gpu/batched_unary_embeddings_ops.py
+-rw-r--r--  2.0 unx      818 b- defN 23-Jul-18 13:00 fbgemm_gpu/enums.py
+-rwxr-xr-x  2.0 unx 10721352 b- defN 23-Jul-18 13:00 fbgemm_gpu/fbgemm_gpu_py.so
+-rw-r--r--  2.0 unx     5648 b- defN 23-Jul-18 13:00 fbgemm_gpu/metrics.py
+-rw-r--r--  2.0 unx     2339 b- defN 23-Jul-18 13:00 fbgemm_gpu/permute_pooled_embedding_modules.py
+-rw-r--r--  2.0 unx     2737 b- defN 23-Jul-18 13:00 fbgemm_gpu/permute_pooled_embedding_modules_split.py
+-rw-r--r--  2.0 unx     7682 b- defN 23-Jul-18 13:00 fbgemm_gpu/quantize_comm.py
+-rw-r--r--  2.0 unx     4005 b- defN 23-Jul-18 13:00 fbgemm_gpu/quantize_utils.py
+-rw-r--r--  2.0 unx     5745 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_embedding_configs.py
+-rw-r--r--  2.0 unx     6661 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_embedding_inference_converter.py
+-rw-r--r--  2.0 unx      525 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_embedding_optimizer_ops.py
+-rw-r--r--  2.0 unx    19751 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_embedding_utils.py
+-rw-r--r--  2.0 unx     2170 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_table_batched_embeddings_ops.py
+-rw-r--r--  2.0 unx     3433 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_table_batched_embeddings_ops_common.py
+-rw-r--r--  2.0 unx    60371 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_table_batched_embeddings_ops_inference.py
+-rw-r--r--  2.0 unx    73634 b- defN 23-Jul-18 13:00 fbgemm_gpu/split_table_batched_embeddings_ops_training.py
+-rw-r--r--  2.0 unx    39550 b- defN 23-Jul-18 13:00 fbgemm_gpu/ssd_split_table_batched_embeddings_ops.py
+-rw-r--r--  2.0 unx      910 b- defN 23-Jul-18 13:00 fbgemm_gpu/uvm.py
+-rw-r--r--  2.0 unx     1603 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/__init__.py
+-rw-r--r--  2.0 unx     4076 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_adagrad.py
+-rw-r--r--  2.0 unx     3291 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_adam.py
+-rw-r--r--  2.0 unx     2775 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_approx_rowwise_adagrad_with_weight_decay.py
+-rw-r--r--  2.0 unx     1906 b- defN 23-Jul-18 12:55 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_args.py
+-rw-r--r--  2.0 unx     3291 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_lamb.py
+-rw-r--r--  2.0 unx     3040 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_lars_sgd.py
+-rw-r--r--  2.0 unx     2316 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_none.py
+-rw-r--r--  2.0 unx     2996 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_partial_rowwise_adam.py
+-rw-r--r--  2.0 unx     2996 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_partial_rowwise_lamb.py
+-rw-r--r--  2.0 unx     4320 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad.py
+-rw-r--r--  2.0 unx     6067 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad_with_counter.py
+-rw-r--r--  2.0 unx     2768 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad_with_weight_decay.py
+-rw-r--r--  2.0 unx     4602 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_weighted_adagrad.py
+-rw-r--r--  2.0 unx     3658 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_sgd.py
+-rw-r--r--  2.0 unx      635 b- defN 23-Jul-18 12:55 fbgemm_gpu/split_embedding_optimizer_codegen/optimizer_args.py
+-rw-r--r--  2.0 unx     6136 b- defN 23-Jul-18 12:58 fbgemm_gpu/split_embedding_optimizer_codegen/split_embedding_optimizer_rowwise_adagrad.py
+-rw-r--r--  2.0 unx     2934 b- defN 23-Jul-18 13:00 fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/METADATA
+-rw-r--r--  2.0 unx      105 b- defN 23-Jul-18 13:00 fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 23-Jul-18 13:00 fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     4534 b- defN 23-Jul-18 13:00 fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/RECORD
+41 files, 11039625 bytes uncompressed, 3192425 bytes compressed:  71.1%
```

## zipnote {}

```diff
@@ -105,20 +105,20 @@
 
 Filename: fbgemm_gpu/split_embedding_optimizer_codegen/optimizer_args.py
 Comment: 
 
 Filename: fbgemm_gpu/split_embedding_optimizer_codegen/split_embedding_optimizer_rowwise_adagrad.py
 Comment: 
 
-Filename: fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/METADATA
+Filename: fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/METADATA
 Comment: 
 
-Filename: fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/WHEEL
+Filename: fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/WHEEL
 Comment: 
 
-Filename: fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/top_level.txt
+Filename: fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/top_level.txt
 Comment: 
 
-Filename: fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/RECORD
+Filename: fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## fbgemm_gpu/fbgemm_gpu_py.so

### strings --all --bytes=8 {}

```diff
@@ -15000,15 +15000,15 @@
 Cvector<bool>::_M_insert_aux
 jvp is not implemented for the c++ API of custom Function yet.
 Please open a feature request on GitHub if you need this.
 /github/home/miniconda/envs/build_binary/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/custom_function.h
 dense_embedding_codegen_lookup_function(Tensor dev_weights, Tensor weights_offsets, Tensor D_offsets, int total_D, int max_D, Tensor hash_size_cumsum, int total_hash_size_bits, Tensor indices, Tensor offsets, int pooling_mode, Tensor? indice_weights, Tensor? feature_requires_grad, int output_dtype=0) -> Tensor
 dense_embedding_codegen_lookup_function
 Cannot update a node's topological_nr after it already has a parent. If we allow this, we can no longer guarantee that a parent's topo_nr is always greater than those of all its children
-!has_parent_ INTERNAL ASSERT FAILED at "/github/home/miniconda/envs/build_binary/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function.h":258, please report a bug to PyTorch. 
+!has_parent_ INTERNAL ASSERT FAILED at "/github/home/miniconda/envs/build_binary/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function.h":263, please report a bug to PyTorch. 
 /github/home/miniconda/envs/build_binary/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function.h
 /__w/FBGEMM/FBGEMM/fbgemm_gpu/codegen/embedding_backward_dense_host_cpu.cpp
 Check failed: grad_outputs.size() == 1 (
  returned an incorrect number of gradients (expected 
  returned a gradient different that is defined at position 
 , but the corresponding forward input was not a Variable
 update_topological_nr
```

### objdump --line-numbers --disassemble --demangle --reloc --no-show-raw-insn --section=.text {}

```diff
@@ -920910,15 +920910,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     53bba0 <c10::Dict<std::string, at::Tensor> c10::impl::toTypedDict<std::string, at::Tensor>(c10::Dict<c10::IValue, c10::IValue>)@@Base+0x33b0>
 	cmpb   $0x0,0x28(%r12)
 	je     53bb43 <c10::Dict<std::string, at::Tensor> c10::impl::toTypedDict<std::string, at::Tensor>(c10::Dict<c10::IValue, c10::IValue>)@@Base+0x3353>
 	lea    0x438e4d(%rip),%r8        
 	lea    0x438f06(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x438fc2(%rip),%rsi        
 	lea    0x439164(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   (%rax)
 	mov    0x4fc459(%rip),%rax        
 	cmpb   $0x0,(%rax)
@@ -921241,15 +921241,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     53c510 <c10::Dict<std::string, at::Tensor> c10::impl::toTypedDict<std::string, at::Tensor>(c10::Dict<c10::IValue, c10::IValue>)@@Base+0x3d20>
 	cmpb   $0x0,0x28(%r12)
 	je     53c368 <c10::Dict<std::string, at::Tensor> c10::impl::toTypedDict<std::string, at::Tensor>(c10::Dict<c10::IValue, c10::IValue>)@@Base+0x3b78>
 	lea    0x438624(%rip),%r8        
 	lea    0x4386dd(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x438799(%rip),%rsi        
 	lea    0x43893b(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r12,%rdi
 	vzeroupper
 	call   149ea0 <torch::autograd::Node::metadata()@plt>
@@ -934150,15 +934150,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     549e90 <std::enable_if<std::is_same<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::value, decltype (fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::apply<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&>(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0x250>
 	cmpb   $0x0,0x28(%r12)
 	je     549e36 <std::enable_if<std::is_same<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::value, decltype (fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::apply<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&>(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0x1f6>
 	lea    0x42ab5a(%rip),%r8        
 	lea    0x42ac13(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x42accf(%rip),%rsi        
 	lea    0x42ae71(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	mov    0x4ee169(%rip),%rax        
 	cmpb   $0x0,(%rax)
 	jne    54a330 <std::enable_if<std::is_same<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::value, decltype (fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::apply<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&>(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0x6f0>
@@ -934339,15 +934339,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     54a398 <std::enable_if<std::is_same<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::value, decltype (fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::apply<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&>(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0x758>
 	cmpb   $0x0,0x28(%r12)
 	je     54a2d0 <std::enable_if<std::is_same<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::value, decltype (fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::apply<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu>, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&>(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0x690>
 	lea    0x42a6bc(%rip),%r8        
 	lea    0x42a775(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x42a831(%rip),%rsi        
 	lea    0x42a9d3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r12,%rdi
 	vzeroupper
 	call   149ea0 <torch::autograd::Node::metadata()@plt>
@@ -943747,15 +943747,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     553f10 <torch::autograd::CppNode<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&)@@Base+0x88a0>
 	cmpb   $0x0,0x28(%r12)
 	je     553e50 <torch::autograd::CppNode<fbgemm_gpu::PermutePooledEmbsFunctionSplit<&fbgemm_gpu::permute_pooled_embs_split_cpu> >::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&)@@Base+0x87e0>
 	lea    0x420b3c(%rip),%r8        
 	lea    0x420bf5(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x420cb1(%rip),%rsi        
 	lea    0x420e53(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4e11a9(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x178(%rbp)
@@ -944586,15 +944586,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     554f10 <fbgemm_gpu::jagged_dense_elementwise_add(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x6a0>
 	cmpb   $0x0,0x28(%r12)
 	je     554e00 <fbgemm_gpu::jagged_dense_elementwise_add(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x590>
 	lea    0x41fb8c(%rip),%r8        
 	lea    0x41fc45(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x41fd01(%rip),%rsi        
 	lea    0x41fea3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4e01f9(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x1b0(%rbp)
@@ -946837,15 +946837,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     557a78 <fbgemm_gpu::jagged_dense_elementwise_add(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x3208>
 	cmpb   $0x0,0x28(%r12)
 	je     5579b0 <fbgemm_gpu::jagged_dense_elementwise_add(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x3140>
 	lea    0x41cfdc(%rip),%r8        
 	lea    0x41d095(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x41d151(%rip),%rsi        
 	lea    0x41d2f3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4dd649(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x1c8(%rbp)
@@ -948521,15 +948521,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     559b30 <fbgemm_gpu::jagged_dense_dense_elementwise_add_jagged_output(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&, at::Tensor const&)@@Base+0x15e0>
 	cmpb   $0x0,0x28(%r13)
 	je     559a70 <fbgemm_gpu::jagged_dense_dense_elementwise_add_jagged_output(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&, at::Tensor const&)@@Base+0x1520>
 	lea    0x41af1f(%rip),%r8        
 	lea    0x41afd8(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x41b094(%rip),%rsi        
 	lea    0x41b236(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4db589(%rip),%rax        
 	mov    %r13,0x8(%r13)
 	mov    %rax,-0x1c0(%rbp)
@@ -950419,15 +950419,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     55c028 <fbgemm_gpu::jagged_dense_elementwise_mul(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x15f8>
 	cmpb   $0x0,0x28(%r12)
 	je     55bf60 <fbgemm_gpu::jagged_dense_elementwise_mul(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x1530>
 	lea    0x418a2c(%rip),%r8        
 	lea    0x418ae5(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x418ba1(%rip),%rsi        
 	lea    0x418d43(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4d9099(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x1c8(%rbp)
@@ -951566,15 +951566,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     55d6b0 <fbgemm_gpu::batched_dense_vec_jagged_2d_mul(at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0xbc0>
 	cmpb   $0x0,0x28(%r12)
 	je     55d5f0 <fbgemm_gpu::batched_dense_vec_jagged_2d_mul(at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0xb00>
 	lea    0x41739c(%rip),%r8        
 	lea    0x417455(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x417511(%rip),%rsi        
 	lea    0x4176b3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4d7a09(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x178(%rbp)
@@ -952151,15 +952151,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     55e250 <fbgemm_gpu::jagged_dense_elementwise_add_jagged_output(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x550>
 	cmpb   $0x0,0x28(%r12)
 	je     55e190 <fbgemm_gpu::jagged_dense_elementwise_add_jagged_output(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x490>
 	lea    0x4167fc(%rip),%r8        
 	lea    0x4168b5(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x416971(%rip),%rsi        
 	lea    0x416b13(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4d6e69(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x180(%rbp)
@@ -954255,15 +954255,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     560b98 <fbgemm_gpu::jagged_dense_elementwise_add_jagged_output(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x2e98>
 	cmpb   $0x0,0x28(%r12)
 	je     560ad0 <fbgemm_gpu::jagged_dense_elementwise_add_jagged_output(at::Tensor const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, at::Tensor const&)@@Base+0x2dd0>
 	lea    0x413ebc(%rip),%r8        
 	lea    0x413f75(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x414031(%rip),%rsi        
 	lea    0x4141d3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4d4529(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x1c8(%rbp)
@@ -955967,15 +955967,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     562d68 <fbgemm_gpu::jagged_jagged_bmm(at::Tensor const&, at::Tensor const&, at::Tensor const&, long)@@Base+0x1628>
 	cmpb   $0x0,0x28(%r12)
 	je     562ca0 <fbgemm_gpu::jagged_jagged_bmm(at::Tensor const&, at::Tensor const&, at::Tensor const&, long)@@Base+0x1560>
 	lea    0x411cec(%rip),%r8        
 	lea    0x411da5(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x411e61(%rip),%rsi        
 	lea    0x412003(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4d2359(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x1c8(%rbp)
@@ -956852,15 +956852,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     563f48 <fbgemm_gpu::jagged_dense_bmm(at::Tensor const&, at::Tensor const&, at::Tensor const&, long)@@Base+0x638>
 	cmpb   $0x0,0x28(%r12)
 	je     563e80 <fbgemm_gpu::jagged_dense_bmm(at::Tensor const&, at::Tensor const&, at::Tensor const&, long)@@Base+0x570>
 	lea    0x410b0c(%rip),%r8        
 	lea    0x410bc5(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x410c81(%rip),%rsi        
 	lea    0x410e23(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4d1179(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x1c0(%rbp)
@@ -958567,15 +958567,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     566160 <fbgemm_gpu::jagged_softmax(at::Tensor const&, at::Tensor const&, long)@@Base+0x16e0>
 	cmpb   $0x0,0x28(%r12)
 	je     5660a0 <fbgemm_gpu::jagged_softmax(at::Tensor const&, at::Tensor const&, long)@@Base+0x1620>
 	lea    0x40e8ec(%rip),%r8        
 	lea    0x40e9a5(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x40ea61(%rip),%rsi        
 	lea    0x40ec03(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4cef59(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x1c0(%rbp)
@@ -960550,15 +960550,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     568978 <fbgemm_gpu::jagged_index_select_2d(at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0x1658>
 	cmpb   $0x0,0x28(%r12)
 	je     5688b0 <fbgemm_gpu::jagged_index_select_2d(at::Tensor const&, at::Tensor const&, at::Tensor const&)@@Base+0x1590>
 	lea    0x40c0dc(%rip),%r8        
 	lea    0x40c195(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x40c251(%rip),%rsi        
 	lea    0x40c3f3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    0x4cc749(%rip),%rax        
 	mov    %r12,0x8(%r12)
 	mov    %rax,-0x2b8(%rbp)
@@ -962534,15 +962534,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     56ab50 <torch::autograd::Node::Node(unsigned long, std::vector<torch::autograd::Edge, std::allocator<torch::autograd::Edge> >&&)@@Base+0x1b0>
 	cmpb   $0x0,0x28(%rbx)
 	je     56aaf8 <torch::autograd::Node::Node(unsigned long, std::vector<torch::autograd::Edge, std::allocator<torch::autograd::Edge> >&&)@@Base+0x158>
 	lea    0x409e9c(%rip),%r8        
 	lea    0x409f55(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x40a011(%rip),%rsi        
 	lea    0x40a1b3(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	xchg   %ax,%ax
 	mov    0x4cd4a9(%rip),%rax        
 	cmpb   $0x0,(%rax)
@@ -1699539,15 +1699539,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     896ad8 <std::enable_if<std::is_same<fbgemm_gpu::PackSegmentsFunction, fbgemm_gpu::PackSegmentsFunction>::value, decltype (fbgemm_gpu::PackSegmentsFunction::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<long const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PackSegmentsFunction>::apply<fbgemm_gpu::PackSegmentsFunction, at::Tensor const&, at::Tensor const&, long const&>(at::Tensor const&, at::Tensor const&, long const&)@@Base+0x248>
 	cmpb   $0x0,0x28(%r12)
 	je     896a78 <std::enable_if<std::is_same<fbgemm_gpu::PackSegmentsFunction, fbgemm_gpu::PackSegmentsFunction>::value, decltype (fbgemm_gpu::PackSegmentsFunction::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<long const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PackSegmentsFunction>::apply<fbgemm_gpu::PackSegmentsFunction, at::Tensor const&, at::Tensor const&, long const&>(at::Tensor const&, at::Tensor const&, long const&)@@Base+0x1e8>
 	lea    0xddf18(%rip),%r8        
 	lea    0xddfd1(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0xde08d(%rip),%rsi        
 	lea    0xde22f(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopw   0x0(%rax,%rax,1)
 	mov    0x1a1521(%rip),%rax        
 	cmpb   $0x0,(%rax)
@@ -1699827,15 +1699827,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8971b8 <std::enable_if<std::is_same<fbgemm_gpu::PackSegmentsFunction, fbgemm_gpu::PackSegmentsFunction>::value, decltype (fbgemm_gpu::PackSegmentsFunction::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<long const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PackSegmentsFunction>::apply<fbgemm_gpu::PackSegmentsFunction, at::Tensor const&, at::Tensor const&, long const&>(at::Tensor const&, at::Tensor const&, long const&)@@Base+0x928>
 	cmpb   $0x0,0x28(%r12)
 	je     897090 <std::enable_if<std::is_same<fbgemm_gpu::PackSegmentsFunction, fbgemm_gpu::PackSegmentsFunction>::value, decltype (fbgemm_gpu::PackSegmentsFunction::forward(decltype(nullptr), (declval<at::Tensor const&>)(), (declval<at::Tensor const&>)(), (declval<long const&>)()))>::type torch::autograd::Function<fbgemm_gpu::PackSegmentsFunction>::apply<fbgemm_gpu::PackSegmentsFunction, at::Tensor const&, at::Tensor const&, long const&>(at::Tensor const&, at::Tensor const&, long const&)@@Base+0x800>
 	lea    0xdd8fc(%rip),%r8        
 	lea    0xdd9b5(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0xdda71(%rip),%rsi        
 	lea    0xddc13(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    (%r14),%rax
 	mov    %r14,%rdi
 	call   *0x10(%rax)
@@ -1742025,15 +1742025,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8c6870 <split_embedding_backward_codegen_dense_cpu(at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, at::Tensor, long, at::Tensor, at::Tensor, long, at::Tensor, double)@@Base+0x6d90>
 	cmpb   $0x0,0x28(%r12)
 	je     8c6816 <split_embedding_backward_codegen_dense_cpu(at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, at::Tensor, long, at::Tensor, at::Tensor, long, at::Tensor, double)@@Base+0x6d36>
 	lea    0xae17a(%rip),%r8        
 	lea    0xae233(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0xae2ef(%rip),%rsi        
 	lea    0xae491(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	mov    0x171789(%rip),%rax        
 	cmpb   $0x0,(%rax)
 	jne    8c7680 <split_embedding_backward_codegen_dense_cpu(at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, at::Tensor, long, at::Tensor, at::Tensor, long, at::Tensor, double)@@Base+0x7ba0>
@@ -1742576,15 +1742576,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8c7828 <split_embedding_backward_codegen_dense_cpu(at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, at::Tensor, long, at::Tensor, at::Tensor, long, at::Tensor, double)@@Base+0x7d48>
 	cmpb   $0x0,0x28(%r12)
 	je     8c7620 <split_embedding_backward_codegen_dense_cpu(at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, at::Tensor, long, at::Tensor, at::Tensor, long, at::Tensor, double)@@Base+0x7b40>
 	lea    0xad36c(%rip),%r8        
 	lea    0xad425(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0xad4e1(%rip),%rsi        
 	lea    0xad683(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r12,%rdi
 	vzeroupper
 	call   149ea0 <torch::autograd::Node::metadata()@plt>
@@ -1748945,15 +1748945,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8ceca0 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, long)>()@@Base+0x35a0>
 	cmpb   $0x0,0x28(%r12)
 	je     8cec44 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, long)>()@@Base+0x3544>
 	lea    0xa5d4c(%rip),%r8        
 	lea    0xa5e05(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0xa5ec1(%rip),%rsi        
 	lea    0xa6063(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	xchg   %ax,%ax
 	mov    0x169359(%rip),%rax        
 	cmpb   $0x0,(%rax)
@@ -1749503,15 +1749503,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8cfc78 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, long)>()@@Base+0x4578>
 	cmpb   $0x0,0x28(%r12)
 	je     8cfa68 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, long)>()@@Base+0x4368>
 	lea    0xa4f24(%rip),%r8        
 	lea    0xa4fdd(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0xa5099(%rip),%rsi        
 	lea    0xa523b(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r12,%rdi
 	vzeroupper
 	call   149ea0 <torch::autograd::Node::metadata()@plt>
@@ -1757224,15 +1757224,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8d8c28 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, double, long)>()@@Base+0x4d88>
 	cmpb   $0x0,0x28(%r12)
 	je     8d8bca <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, double, long)>()@@Base+0x4d2a>
 	lea    0x9bdc6(%rip),%r8        
 	lea    0x9be7f(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x9bf3b(%rip),%rsi        
 	lea    0x9c0dd(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax)
 	mov    0x15f3d1(%rip),%rax        
 	cmpb   $0x0,(%rax)
@@ -1757827,15 +1757827,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8d9cb8 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, double, long)>()@@Base+0x5e18>
 	cmpb   $0x0,0x28(%r12)
 	je     8d9ab0 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, double, long)>()@@Base+0x5c10>
 	lea    0x9aedc(%rip),%r8        
 	lea    0x9af95(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x9b051(%rip),%rsi        
 	lea    0x9b1f3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r12,%rdi
 	vzeroupper
 	call   149ea0 <torch::autograd::Node::metadata()@plt>
@@ -1764390,15 +1764390,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8e1700 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long, long, double, long, long, long, double, double, long, long)>()@@Base+0x35a0>
 	cmpb   $0x0,0x28(%r12)
 	je     8e169c <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long, long, double, long, long, long, double, double, long, long)>()@@Base+0x353c>
 	lea    0x932f4(%rip),%r8        
 	lea    0x933ad(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x93469(%rip),%rsi        
 	lea    0x9360b(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	cs nopw 0x0(%rax,%rax,1)
 	mov    0x1568f9(%rip),%rax        
 	cmpb   $0x0,(%rax)
@@ -1764946,15 +1764946,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8e26c8 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long, long, double, long, long, long, double, double, long, long)>()@@Base+0x4568>
 	cmpb   $0x0,0x28(%r12)
 	je     8e24c0 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long, long, double, long, long, long, double, double, long, long)>()@@Base+0x4360>
 	lea    0x924cc(%rip),%r8        
 	lea    0x92585(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x92641(%rip),%rsi        
 	lea    0x927e3(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r12,%rdi
 	vzeroupper
 	call   149ea0 <torch::autograd::Node::metadata()@plt>
@@ -1771367,15 +1771367,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8e9c90 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long)>()@@Base+0x3500>
 	cmpb   $0x0,0x28(%r12)
 	je     8e9c33 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long)>()@@Base+0x34a3>
 	lea    0x8ad5d(%rip),%r8        
 	lea    0x8ae16(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x8aed2(%rip),%rsi        
 	lea    0x8b074(%rip),%rdi        
 	vzeroupper
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   (%rax)
 	mov    0x14e369(%rip),%rax        
 	cmpb   $0x0,(%rax)
@@ -1771730,15 +1771730,15 @@
 	add    $0x18,%rax
 	cmp    %rax,%rcx
 	je     8ea6d8 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long)>()@@Base+0x3f48>
 	cmpb   $0x0,0x28(%r12)
 	je     8ea540 <std::unique_ptr<c10::FunctionSchema, std::default_delete<c10::FunctionSchema> > c10::detail::inferFunctionSchemaFromFunctor<at::Tensor (at::Tensor, at::Tensor, at::Tensor, at::Tensor, long, long, at::Tensor, long, at::Tensor, at::Tensor, long, c10::optional<at::Tensor>, c10::optional<at::Tensor>, bool, double, bool, at::Tensor, at::Tensor, at::Tensor, double, double, double, long, long)>()@@Base+0x3db0>
 	lea    0x8a44c(%rip),%r8        
 	lea    0x8a505(%rip),%rcx        
-	mov    $0x102,%edx
+	mov    $0x107,%edx
 	lea    0x8a5c1(%rip),%rsi        
 	lea    0x8a763(%rip),%rdi        
 	call   1475b0 <c10::detail::torchInternalAssertFail(char const*, char const*, unsigned int, char const*, char const*)@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r12,%rdi
 	vzeroupper
 	call   149ea0 <torch::autograd::Node::metadata()@plt>
```

### readelf --wide --decompress --hex-dump=.rodata {}

```diff
@@ -10926,15 +10926,15 @@
   0x00974ab0 2f676974 6875622f 686f6d65 2f6d696e /github/home/min
   0x00974ac0 69636f6e 64612f65 6e76732f 6275696c iconda/envs/buil
   0x00974ad0 645f6269 6e617279 2f6c6962 2f707974 d_binary/lib/pyt
   0x00974ae0 686f6e33 2e392f73 6974652d 7061636b hon3.9/site-pack
   0x00974af0 61676573 2f746f72 63682f69 6e636c75 ages/torch/inclu
   0x00974b00 64652f74 6f726368 2f637372 632f6175 de/torch/csrc/au
   0x00974b10 746f6772 61642f66 756e6374 696f6e2e tograd/function.
-  0x00974b20 68223a32 35382c20 706c6561 73652072 h":258, please r
+  0x00974b20 68223a32 36332c20 706c6561 73652072 h":263, please r
   0x00974b30 65706f72 74206120 62756720 746f2050 eport a bug to P
   0x00974b40 79546f72 63682e20 00000000 00000000 yTorch. ........
   0x00974b50 2f676974 6875622f 686f6d65 2f6d696e /github/home/min
   0x00974b60 69636f6e 64612f65 6e76732f 6275696c iconda/envs/buil
   0x00974b70 645f6269 6e617279 2f6c6962 2f707974 d_binary/lib/pyt
   0x00974b80 686f6e33 2e392f73 6974652d 7061636b hon3.9/site-pack
   0x00974b90 61676573 2f746f72 63682f69 6e636c75 ages/torch/inclu
```

## Comparing `fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/METADATA` & `fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: fbgemm-gpu-nightly-cpu
-Version: 2023.7.17
+Version: 2023.7.18
 Home-page: https://github.com/pytorch/fbgemm
 Author: FBGEMM Team
 Author-email: packages@pytorch.org
 License: BSD-3
 Keywords: PyTorch,Recommendation Models,High Performance Computing,GPU,CUDA
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
```

## Comparing `fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/RECORD` & `fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 fbgemm_gpu/__init__.py,sha256=hyPNE6QvlwUNM4PlyfKee7j7agkOF2SNoT3EQXJ-pe0,567
 fbgemm_gpu/_fbgemm_gpu_docs.py,sha256=ks59ZF1sbng7P2uhG_taag5310ml9N_y4jU0EDsUhXs,14920
 fbgemm_gpu/batched_unary_embeddings_ops.py,sha256=rc49BZwtZuu8qsO5MENAlHeswgPUn35aM8Cgr3XtBE0,2747
 fbgemm_gpu/enums.py,sha256=Tg1pBJrcfSIWmWec2WCZkRuMwmCnepKrcACi3ZijZmk,818
-fbgemm_gpu/fbgemm_gpu_py.so,sha256=Dx12wvHZVDsJpO6Hq9s0-XAHxelKi-ghbdb-KS7zqe0,10721352
+fbgemm_gpu/fbgemm_gpu_py.so,sha256=nAYu0ft6eQaKG6w2oTQaebTdYIcrL2SqdZFe2CUUco8,10721352
 fbgemm_gpu/metrics.py,sha256=e5VnTatZjFqcgOfipH7Eqk5lsAkuxY2qsbil3Csy_yk,5648
 fbgemm_gpu/permute_pooled_embedding_modules.py,sha256=n80gTkNwSA9k0dvJeZhVjzXC08c74o0G-u4MnKs7rek,2339
 fbgemm_gpu/permute_pooled_embedding_modules_split.py,sha256=5i6X51URDXoUQnxa1EvQdQ0WMhh_4dq4vsLozDiNmQQ,2737
 fbgemm_gpu/quantize_comm.py,sha256=qONCevOTVA89K7vFJe-Bcc903lHsKDg6s661pTHCF2k,7682
 fbgemm_gpu/quantize_utils.py,sha256=pnZCkIeYxPnvwkIVsRdfPeGBLVXSpEdSsFLH2Ygk7D0,4005
 fbgemm_gpu/split_embedding_configs.py,sha256=Y3fJLHh4ffO6v_iKGc2MbBQTu8yFIMExEG_VYNW7rzI,5745
 fbgemm_gpu/split_embedding_inference_converter.py,sha256=z1NugAsdcLO4nVFa_DJlOZHahmEdrBELi15ywFdaP3U,6661
@@ -31,11 +31,11 @@
 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad.py,sha256=ToqlGd9bLtY0OtUZr7JnaujeLgIcI2mAoCcPeaMVn1s,4320
 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad_with_counter.py,sha256=PVePhoU52wiFE_1gdZezHBiqsjiwJjzn2JBLEW3X2uk,6067
 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_adagrad_with_weight_decay.py,sha256=lUEZjp4C3HxSizRXKr47gAV1hgBtGqENVSFqNo5NtA0,2768
 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_rowwise_weighted_adagrad.py,sha256=2U09t7mznAY-6HosMRX5kqplVO-HETHt4gKI26jjQXs,4602
 fbgemm_gpu/split_embedding_codegen_lookup_invokers/lookup_sgd.py,sha256=wv_Sdrifrrcw2hsgRwNCGsma6roIU5hXiEzpct4bmrc,3658
 fbgemm_gpu/split_embedding_optimizer_codegen/optimizer_args.py,sha256=I6xnQ0vv6PZCxMsR87fWvb1Qtkp7ehx1b-9-La1vW2U,635
 fbgemm_gpu/split_embedding_optimizer_codegen/split_embedding_optimizer_rowwise_adagrad.py,sha256=soARoBsdOnNNZdCIkVmryPHtKyhbcFLqHOTveG-hk6s,6136
-fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/METADATA,sha256=1ko1I9vZMEOrqKEmkGiQHgG9Wn2pK9ZQNTh_blBYdlw,2934
-fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/WHEEL,sha256=uNTrmykJsfnOiRowEmEAgdbSsr7BScgAFZq1d9YxSqA,105
-fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/top_level.txt,sha256=2tlbTWLkPjhqvLF_6BbqKzkcPluSE-oPRVjI8axK76I,11
-fbgemm_gpu_nightly_cpu-2023.7.17.dist-info/RECORD,,
+fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/METADATA,sha256=6x8LPCUl2dD0H1_pBpIeRs36JkkUF8-3Q_0cHTPSN30,2934
+fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/WHEEL,sha256=uNTrmykJsfnOiRowEmEAgdbSsr7BScgAFZq1d9YxSqA,105
+fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/top_level.txt,sha256=2tlbTWLkPjhqvLF_6BbqKzkcPluSE-oPRVjI8axK76I,11
+fbgemm_gpu_nightly_cpu-2023.7.18.dist-info/RECORD,,
```

